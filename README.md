| Language | [English](#english)  | [TÃ¼rkÃ§e](#tÃ¼rkÃ§e) |
|-----------|-------------|---------|

## <a name="english"></a>

# ğŸš Drone Delivery System with Deep Q-Network (DQN)

<div align="center">
  <p><em>Intelligent Package Delivery System with Deep Reinforcement Learning</em></p>
</div>

---

## ğŸ“– About the Project

This project is an intelligent drone simulator that optimizes urban package deliveries using the **Deep Q-Network (DQN)** algorithm. Drones pick up packages from the cargo depot and learn the most efficient routes to deliver them to multiple delivery points through neural network-based decision making.

### ğŸ¯ Project Goals
- Simulate real-world logistics problems with deep learning
- Demonstrate practical application of the DQN algorithm
- Observe the learning process with an interactive visual interface
- Experiment with neural network parameters to achieve the best results

## âœ¨ Features

- ğŸ§  **Deep Q-Network (DQN)** with PyTorch neural networks
- ğŸ”„ **Experience Replay** and **Target Network** for stable learning
- ğŸ® **Interactive Simulation** with real-time animations  
- ğŸ¯ **Manual & AI Modes** - Control drone or watch AI performance
- ğŸ’¾ **Model Management** - Save/load trained neural networks (.pth format)
  
### ğŸ“Š Simulation Details
- ğŸŸ¢ **Cargo Depot**: Bottom-right corner where packages are picked up
- ğŸ”´ **Delivery Points**: Randomly placed target locations (1-3 per episode)
- ğŸ”µ **Drone**: Intelligent agent (battery, cargo status display)
- ğŸ”‹ **Battery Management**: Different energy costs for movement, takeoff, landing

### ğŸ’¾ Model Management
- **Save/Load DQN Model**: Store trained neural networks (.pth files)
- **Training Statistics**: Track reward and steps per episode
- **Speed Settings**: Control training and simulation speeds

## ğŸ› ï¸ Technology Stack

- **Python 3.10+** - Main programming language
- **PyQt5** - GUI framework  
- **PyTorch** - Deep learning framework
- **NumPy** - Numerical computations

## ğŸš€ Installation

```bash
# Python 3.10 or higher is required
python --version

# 1. Clone the Project
git clone https://github.com/FerhatAkalan/DroneDeliverySystemDQN.git
cd DroneDeliverySystemDQN

# 2. Install Dependencies
pip install -r requirements.txt

# 3. Start the Simulator
python drone_delivery_system.py
```

## ğŸ§  Deep Q-Network Algorithm

### ğŸ—ï¸ Neural Network Architecture
- **Input Layer**: 12 neurons (state vector)
- **Hidden Layer**: 128 neurons + ReLU + Dropout(0.2)
- **Output Layer**: 6 neurons (Q-values for actions)

### ğŸ“Š State Representation (12D Vector)
The DQN uses a 12-dimensional state vector containing:
- **Drone Position**: Normalized x, y coordinates (0-1)
- **Drone Status**: Has cargo (0/1), is flying (0/1)
- **Battery Level**: Normalized battery percentage (0-1)
- **Cargo Depot**: Normalized x, y coordinates (0-1)
- **Target Information**: Nearest delivery point position and distance
- **Environmental Data**: Target count, step count, done flags

### ğŸ”„ Action Space
| Action | Description | Condition |
|--------|-------------|-----------|
| `0` â¬‡ï¸ | Move down | Drone must be flying |
| `1` â¡ï¸ | Move right | Drone must be flying |
| `2` â¬†ï¸ | Move up | Drone must be flying |
| `3` â¬…ï¸ | Move left | Drone must be flying |
| `4` ğŸ“¦ | Pick/Drop cargo | Drone must be on the ground |
| `5` ğŸ›«ğŸ›¬ | Takeoff/Land | Always available |

### ğŸ† Optimized Reward System

#### âœ… Positive Rewards
- **Pick up cargo**: +200 points (increased for better learning)
- **Successful delivery**: +1000 points (significantly increased)
- **Task completion**: +500 points + battery bonus
- **Approaching target**: +10 points per step (doubled)
- **Near depot bonus**: +15 points when close to depot and grounded
- **Correct action bonus**: +10 points for right action at right place

#### âŒ Penalties (Reduced for Better Learning)
- **Invalid action**: -0.5 to -2 points (much reduced)
- **Move away from target**: -1 point per step (halved)
- **Battery depletion**: -50 points
- **Timeout**: -20 points
- **Movement cost**: -0.2 points per move (minimal)

## ğŸ“¸ Project Image
![Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2025-07-08 115233](https://github.com/user-attachments/assets/e5330c90-afcf-4b35-9ab4-657bd4782525)


### âš™ï¸ DQN Hyperparameters
- **Learning Rate**: 0.001
- **Discount Factor (Î³)**: 0.99
- **Epsilon Decay**: 0.995
- **Batch Size**: 32
- **Replay Buffer Size**: 10,000
- **Target Network Update**: Every 100 steps
- **Default Training Episodes**: 20,000

## ğŸ”¬ Experimental Results

### ğŸ“Š Training Performance
- **Grid Size**: 5x5 (default optimal setting)
- **Recommended Training**: 20,000 episodes for stable performance
- **Success Rate**: 85%+ after proper training
- **State Representation**: 12D vector for efficient learning

### ğŸ“ˆ Learning Curve
As training progresses, drone performance increases significantly:
- **First 5,000 episodes**: Random exploration behavior
- **5,000-15,000 episodes**: Learning pickup and delivery strategy
- **15,000+ episodes**: Optimized route planning and battery management

### ğŸ¯ Performance Metrics
- **Average Reward**: Steadily increases from negative to positive values
- **Episode Length**: Decreases as drone learns efficient paths
- **Battery Usage**: Optimized energy consumption patterns
- **Success Rate**: Reaches 90%+ completion rate after full training

## ğŸ¤ Contributing

If you want to contribute to this project:

1. **Fork** it
2. **Create a feature branch** (`git checkout -b feature/NewFeature`)
3. **Commit** (`git commit -am 'Add new feature'`)
4. **Push** (`git push origin feature/NewFeature`)
5. **Create a Pull Request**

### ğŸ’¡ Contribution Areas

| ğŸš€ Feature | ğŸ“ Description | ğŸ¯ Difficulty |
|-----------|---------------|--------------|
| **Obstacle System** | Add obstacles and environmental hazards | ğŸŸ¡ Medium |
| **Multi-Agent DQN** | Multiple drones learning simultaneously | ğŸ”´ Hard |
| **Double DQN** | Improved DQN with double Q-learning | ï¿½ Medium |
| **3D Visualization** | 3D environment rendering | ğŸŸ¡ Medium |
| **Real-Time Statistics** | Live training metrics with Matplotlib | ğŸŸ¢ Easy |
| **Advanced Rewards** | Complex reward shaping and curriculum learning | ï¿½ Hard |

---

<div align="center">
  <h3>â­ If you like the project, don't forget to give a star! â­</h3>  
  <p>If you have any questions, you can <a href="https://github.com/FerhatAkalan/DroneDeliverySystemDQN/issues">open an issue</a>.</p>
  
  **ğŸš Happy Coding! ğŸš**
  
  <sub>Made with â¤ï¸ by Ferhat Akalan</sub>
</div>

---

</br>

---

## <a name="tÃ¼rkÃ§e"></a>

# ğŸš Deep Q-Network ile Drone Teslimat Sistemi

<div align="center">
  <p><em>Derin PekiÅŸtirmeli Ã–ÄŸrenme ile AkÄ±llÄ± Paket Teslimat Sistemi</em></p>
</div>

---

## ğŸ“– Proje HakkÄ±nda

Bu proje, **Deep Q-Network (DQN)** algoritmasÄ± kullanarak ÅŸehir iÃ§i paket teslimatlarÄ±nÄ± optimize eden akÄ±llÄ± bir dron simÃ¼latÃ¶rÃ¼dÃ¼r. Dronlar, neural network tabanlÄ± karar verme ile kargo deposundan paketleri alÄ±p birden fazla teslimat noktasÄ±na en verimli rotalarÄ± Ã¶ÄŸrenerek ulaÅŸtÄ±rÄ±rlar.

### ğŸ¯ Proje Hedefleri
- GerÃ§ek dÃ¼nya lojistik problemlerini derin Ã¶ÄŸrenme ile simÃ¼le etmek
- DQN algoritmasÄ±nÄ±n pratik uygulamasÄ±nÄ± gÃ¶stermek  
- Ä°nteraktif gÃ¶rsel arayÃ¼z ile Ã¶ÄŸrenme sÃ¼recini gÃ¶zlemlemek
- Neural network parametrelerini deneyimleyerek en iyi sonuÃ§larÄ± elde etmek          

## âœ¨ Ã–zellikler

- ğŸ§  **Deep Q-Network (DQN)** PyTorch neural network'leri ile
- ğŸ”„ **Experience Replay** ve **Target Network** ile kararlÄ± Ã¶ÄŸrenme
- ğŸ® **Ä°nteraktif SimÃ¼lasyon** gerÃ§ek zamanlÄ± animasyonlarla
- ğŸ¯ **Manuel & AI ModlarÄ±** - Drone kontrolÃ¼ veya AI performansÄ± izleme
- ğŸ’¾ **Model YÃ¶netimi** - EÄŸitilmiÅŸ neural network'leri kaydetme/yÃ¼kleme (.pth format)

### ğŸ“Š SimÃ¼lasyon DetaylarÄ±
- ğŸŸ¢ **Kargo Deposu**: SaÄŸ alt kÃ¶ÅŸede paketlerin alÄ±ndÄ±ÄŸÄ± merkez
- ğŸ”´ **Teslimat NoktalarÄ±**: Rastgele yerleÅŸtirilen hedef lokasyonlar (episode baÅŸÄ±na 1-3 adet)
- ğŸ”µ **Drone**: AkÄ±llÄ± ajan (batarya, kargo durumu gÃ¶sterimi)
- ğŸ”‹ **Batarya YÃ¶netimi**: Hareket, kalkÄ±ÅŸ, iniÅŸ iÃ§in farklÄ± enerji maliyetleri

## ğŸ› ï¸ Teknoloji Stack

- **Python 3.10+** - Ana programlama dili
- **PyQt5** - GUI framework
- **PyTorch** - Derin Ã¶ÄŸrenme framework'Ã¼
- **NumPy** - SayÄ±sal hesaplamalar

## ğŸš€ Kurulum

```bash
# Python 3.10 veya Ã¼zeri gereklidir
python --version

# 1. Projeyi KlonlayÄ±n
git clone https://github.com/FerhatAkalan/DroneDeliverySystemDQN.git
cd DroneDeliverySystemDQN

# 2. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin
pip install -r requirements.txt

# 3. SimÃ¼latÃ¶rÃ¼ BaÅŸlatÄ±n
python drone_delivery_system.py
```

## ğŸ§  Deep Q-Network AlgoritmasÄ±

### ğŸ—ï¸ Neural Network Mimarisi
- **GiriÅŸ KatmanÄ±**: 12 nÃ¶ron (durum vektÃ¶rÃ¼)
- **Gizli Katman**: 128 nÃ¶ron + ReLU + Dropout(0.2)
- **Ã‡Ä±kÄ±ÅŸ KatmanÄ±**: 6 nÃ¶ron (Q-deÄŸerleri)

### ğŸ“Š Durum Temsili (12 Boyutlu VektÃ¶r)
DQN ÅŸu bilgileri iÃ§eren 12 boyutlu durum vektÃ¶rÃ¼ kullanÄ±r:
- **Drone Pozisyonu**: Normalize edilmiÅŸ x, y koordinatlarÄ± (0-1)
- **Drone Durumu**: Kargo var mÄ± (0/1), uÃ§uyor mu (0/1)
- **Batarya Seviyesi**: Normalize edilmiÅŸ batarya yÃ¼zdesi (0-1)
- **Kargo Deposu**: Normalize edilmiÅŸ x, y koordinatlarÄ± (0-1)
- **Hedef Bilgisi**: En yakÄ±n teslimat noktasÄ± pozisyonu ve mesafe
- **Ã‡evresel Veri**: Hedef sayÄ±sÄ±, adÄ±m sayÄ±sÄ±, tamamlanma durumu

### ğŸ”„ Eylem UzayÄ±
| Eylem | AÃ§Ä±klama | KoÅŸul |
|-------|----------|-------|
| `0` â¬‡ï¸ | AÅŸaÄŸÄ± hareket | Drone havada olmalÄ± |
| `1` â¡ï¸ | SaÄŸa hareket | Drone havada olmalÄ± |
| `2` â¬†ï¸ | YukarÄ± hareket | Drone havada olmalÄ± |
| `3` â¬…ï¸ | Sola hareket | Drone havada olmalÄ± |
| `4` ğŸ“¦ | Kargo al/bÄ±rak | Drone yerde olmalÄ± |
| `5` ğŸ›«ğŸ›¬ | KalkÄ±ÅŸ/Ä°niÅŸ | Her zaman kullanÄ±labilir |

### ğŸ† Ã–dÃ¼l Sistemi

#### âœ… Pozitif Ã–dÃ¼ller
- **Kargo alma**: +100 puan
- **BaÅŸarÄ±lÄ± teslimat**: +500 puan
- **GÃ¶rev tamamlama**: +1000 puan + batarya bonusu
- **Hedefe yaklaÅŸma**: +5 puan/adÄ±m
- **Hedefe ulaÅŸma**: Mesafe tabanlÄ± bonus

#### âŒ Cezalar
- **GeÃ§ersiz eylem**: -1 ile -10 puan arasÄ±
- **Hedeften uzaklaÅŸma**: -2 puan/adÄ±m
- **Batarya bitimi**: -50 puan
- **Zaman aÅŸÄ±mÄ±**: -20 puan
- **SÄ±nÄ±r ihlali**: -1 puan
  
## ğŸ“¸ Proje GÃ¶rseli
![Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2025-07-08 115233](https://github.com/user-attachments/assets/e5330c90-afcf-4b35-9ab4-657bd4782525)

### âš™ï¸ DQN Hiperparametreleri
- **Ã–ÄŸrenme OranÄ±**: 0.001
- **Ä°ndirgeme FaktÃ¶rÃ¼ (Î³)**: 0.99
- **Epsilon Azalma**: 0.995
- **Batch Boyutu**: 32
- **Replay Buffer Boyutu**: 10,000
- **Target Network GÃ¼ncelleme**: Her 100 adÄ±mda
- **VarsayÄ±lan EÄŸitim Episode**: 20,000

## ğŸ”¬ Deneysel SonuÃ§lar

### ğŸ“Š EÄŸitim PerformansÄ±
- **Grid Boyutu**: 5x5 (varsayÄ±lan optimal ayar)
- **Ã–nerilen EÄŸitim**: KararlÄ± performans iÃ§in 20,000 episode
- **BaÅŸarÄ± OranÄ±**: Uygun eÄŸitim sonrasÄ± %85+
- **Durum Temsili**: Verimli Ã¶ÄŸrenme iÃ§in 12 boyutlu vektÃ¶r

### ğŸ“ˆ Ã–ÄŸrenme EÄŸrisi
EÄŸitim ilerledikÃ§e dronun performansÄ± belirgin ÅŸekilde artar:
- **Ä°lk 5,000 episode**: Rastgele keÅŸif davranÄ±ÅŸÄ±
- **5,000-15,000 episode**: Kargo alma ve teslimat stratejisi Ã¶ÄŸrenme
- **15,000+ episode**: Optimize edilmiÅŸ rota planlama ve batarya yÃ¶netimi

### ğŸ¯ Performans Metrikleri
- **Ortalama Ã–dÃ¼l**: Negatif deÄŸerlerden pozitif deÄŸerlere sÃ¼rekli artÄ±ÅŸ
- **Episode SÃ¼resi**: Drone verimli yollar Ã¶ÄŸrendikÃ§e azalÄ±r
- **Batarya KullanÄ±mÄ±**: Optimize edilmiÅŸ enerji tÃ¼ketim kalÄ±plarÄ±
- **BaÅŸarÄ± OranÄ±**: Tam eÄŸitim sonrasÄ± %90+ tamamlanma oranÄ±

## ğŸ¤ KatkÄ±da Bulunma

Bu projeye katkÄ±da bulunmak istiyorsanÄ±z:

1. **Fork** edin
2. **Feature branch** oluÅŸturun (`git checkout -b feature/NewFeature`)
3. **Commit** edin (`git commit -am 'Add new feature'`)
4. **Push** edin (`git push origin feature/NewFeature`)
5. **Pull Request** oluÅŸturun

### ğŸ’¡ KatkÄ± AlanlarÄ±

| ğŸš€ Ã–zellik | ğŸ“ AÃ§Ä±klama | ğŸ¯ Zorluk |    
|-----------|-------------|----------|    
| **Engel Sistemi** | Engeller ve Ã§evresel tehlikeler ekleme | ğŸŸ¡ Orta |    
| **Ã‡ok AjanlÄ± DQN** | AynÄ± anda birden fazla drone Ã¶ÄŸrenmesi | ğŸ”´ Zor |    
| **Double DQN** | Ã‡ifte Q-Ã¶ÄŸrenme ile geliÅŸtirilmiÅŸ DQN | ï¿½ Orta |    
| **3D GÃ¶rselleÅŸtirme** | 3D ortam render etme | ğŸŸ¡ Orta |    
| **GerÃ§ek ZamanlÄ± Ä°statistikler** | Matplotlib ile canlÄ± eÄŸitim metrikleri | ğŸŸ¢ Kolay |    
| **GeliÅŸmiÅŸ Ã–dÃ¼ller** | KarmaÅŸÄ±k Ã¶dÃ¼l ÅŸekillendirme ve mÃ¼fredat Ã¶ÄŸrenmesi | ï¿½ Zor |

---

<div align="center">
  <h3>â­ Projeyi beÄŸendiyseniz star vermeyi unutmayÄ±n! â­</h3>
  <p>Herhangi bir sorunuz varsa <a href="https://github.com/FerhatAkalan/DroneDeliverySystemDQN/issues">issue aÃ§abilirsiniz</a>.</p>
  
  **ğŸš Happy Coding! ğŸš**
  
  <sub>Made with â¤ï¸ by Ferhat Akalan</sub>
</div>
